#!/usr/bin/env python
# pylint: disable=C0103
"""
问题描述:
    面试官让写个程序来玩Fizz Buzz. 这是一个游戏。玩家从1数到100，如果数字被3整除，那么喊'fizz'，
    如果被5整除就喊'buzz'，如果两个都满足就喊'fizzbuzz'，不然就直接说数字。这个游戏玩起来就像是：
    > 1 2 fizz 4 buzz fizz 7 8 fizz buzz 11 fizz 13 14 fizzbuzz 16 ...

作业目的:
    理解老师给的代码示例
方式:
    构造不同的特征向量,对比不同特征向量下对预测值与真值间的误差
    特征1: 使用输入的x本身作为一维特征向量的分量构造特征向量
    特征2: 使用x对3,5,15的取余计算结果作为特征向量的分量
    特征3: 使用x对3,5的取余计算结果作为特征向量的分量
    特征4: 判断x对3,5的取余计算结果是否为0,为0--->分量为1,不为0--->分量为0
    特征5: 判断x对3,5的取余计算结果是否不为0,为0--->分量为0,不为0--->分量为1
实验结果:
    特征1: 
        均方误差为 0.84,
        第一次实验(训练集101~200),  预测值中每一项都是0.717171717172,
        第二次实验(训练集101~600),  最小值为0.731462925852,最大值为0.732256513026
        第三次实验(训练集101~900),  最小值为0.732165206508,最大值为0.732474968711
        第四次实验(训练集101~10000),最小值为0.733102312749,最大值为0.733104333563
    特征2: 
        均方误差为 0.38,预测值中每一项都是小数,范围在-1 < y_pred < 3,
        第一次实验(训练集101~200)   最小值为-0.585822755685,最大值为2.03605348263
        第二次实验(训练集101~600)   最小值为-0.566193716618,最大值为2.03033996151
        第三次实验(训练集101~900)   最小值为-0.566380318142,最大值为2.03146872735
        第四次实验(训练集101~10000) 最小值为-0.566678456612,最大值为2.03325080372
    特征3: 
        均方误差为 0.38,预测值中每一项都是小数,范围在-1 < y_pred < 3,
        第一次实验(训练集101~200)   最小值为-0.583118490255,最大值为2.03342020806
        第二次实验(训练集101~600)   最小值为-0.564560345614,最大值为2.0286750458
        第三次实验(训练集101~600)   最小值为-0.565351705498,最大值为2.03042777494
        第四次实验(训练集101~10000),最小值为-0.566619514331,最大值为2.03319187633
    特征4: 
        均方误差为 0.00,
        第一次实验(训练集101~200),  预测值与真实值完全相同
        第二次实验(训练集101~600),  最小值为1.22124532709e-15,最大值为3.0
        第三次实验(训练集101~900),  最小值为-6.66133814775e-16,最大值为3.0
        第四次实验(训练集101~10000),最小值为5.99520433298e-15,最大值为3.0
    特征5: 
        均方误差为 0.00,预测值与真是值基本相同,范围在0 < y_pred < 3,
        第一次实验(训练集101~200),  最小值为4.4408920985e-16 可以近似的认为是0,最大值为3.0
        第二次实验(训练集101~600),  最小值为1.33226762955e-15,最大值为3.0
        第三次实验(训练集101~900),  最小值为-8.881784197e-16,最大值为3.0
        第四次实验(训练集101~10000),最小值为5.77315972805e-15,最大值为3.0
结果分析:
    特征1:
        特征构建方法等于没有构建任何特征,特征向量对预测结果没有任何影响.
    特征2:
        分析问题发现,输入的数值x对于3,5.15的余数有关,因此取x对3,5,15的余数作为特征向量的分量
        其试验结果中均方误差明显减小.
    特征3:
        对特征2进行进一步分析,发现数值x对于15的余数为0时,x对于3和5的余数一定为0,
        所以x对于15的余数取值取决于x对于3和5的余数的值是同时为0,其对预测结果的影响同样取决于x对3和5的余数
        因此考虑从特征2的三维向量降维到二维,也就是,去掉x对于15的余数这一分量.
        其实实验结果证明,特征3与特征二在训练上是等效的.(特征3与特征2的最小值与最大值的差距虽然不大,
        但是特征3要更精准一些)
    特征4:
        结合问题,并在特征2的基础上分析发现,当x对于3和5的余数不为0时预测值都是0,因此当余数不为0时,
        余数是多少并不影响预测值的取值,所以,考虑这样的特征向量[a,b],a和b分别表示x对于3和5的余数是否为0,
        取值为0和1,当余数为0时取值为1,当不为0时取值为0.使用这样的向量进行训练和测试,结果出乎意料的好.
        但是经过4个不同的训练集实验发现,当训练集较大时预测值的结果反而不稳定.
    特征5:
        将特征4中a,b的取值条件反过来构建特征向量,以此来进行训练和测试,发现效果与特征4相仿.比较4次实验
        两种特征下取得的预测值的最小值,发现特征4貌似更稳定一下.

    结论:
        1. 当提取的特征的对于预测结果的影响更直接,更明确时,使用它得到的分类器的预测效果更好一些.
        2. 训练集的元素数量多少在一定程度上影响分类器的训练效果,但并不是元素越多越好.
        3. 当提取的特征对于预测结果的影响更加趋于直接,趋于明确时,训练集的数量对于训练效果的影响也将可以忽略不计
        4. 在分析特征时,应该分析特征之间是否相互影响.找出被其他特征影响的特征,可以将这些被影响的特征从特征集合中
        抽取,也可以将它们与其他特征合并成新的特征,从而实现特征向量降维的目的.最后得到的特征向量个分量之间应该是
        两两之间互不相关的.
    
存在的问题:
    1. 如何从大量数据中筛选出合适的训练集?
    2. 在这个问题的四次实验上,测试集完全相同.那么,在现实环境中,应该如何选择才能真正测试分类器的预测效果的优劣?
       进而进一步修正特征的提取?
    3. 在对现实当中的问题做特征工程时,应该如何将提取的特征映射成对应的数值?过程中应该注意什么?
"""

import numpy as np
import sklearn.linear_model as linear_model
from sklearn.metrics import mean_squared_error


def feature_with_self(i):
    """
    构造输入数字的一维特征向量,向量分量是数字本身
        :param i: 输入的数字
        :returns: ndarray 构造的特征向量
    """
    return np.array([i])


def feature_with_complementation(i):
    """
    构造输入数字的三维特征向量,向量分量分别是数字对3,5,15的取余计算结果
        :param i: 输入的数字
        :returns: ndarray 构造的三维特征向量
    """
    return np.array([i % 3, i % 5, i % 15])


def feature_with_complementation2(i):
    """
    构造输入数字的二维特征向量,向量分量分别是数字对3,5的取余计算结果
        :param i: 输入的数字
        :returns: ndarray 构造的二维特征向量
    """
    return np.array([i % 3, i % 5])


def feature_complementation_is_zero(i):
    """
    构造输入数字的二维特征向量,当输入的数字对3或5的取余计算结果为0时,对应分量为1,否则分量为0
        :param i: 输入的数字
        :returns: ndarray 构造的二维特征向量
    """
    return np.array([1 if i % 3 == 0 else 0,
                     1 if i % 5 == 0 else 0])


def feature_complementation_isnot_zero(i):
    """
    构造输入数字的二维特征向量,当输入的数字对3或5的取余计算结果为0时,对应分量为0,否则分量为1
    与feature_complementation_is_zero的构造方法相反
        :param i: 输入的数字
        :returns: ndarray 构造的二维特征向量
    """
    return np.array([1 if i % 3 != 0 else 0,
                     1 if i % 5 != 0 else 0])


def construct_sample_label(i):
    """
    对预测的真值结果映射成数字,以便计算机进行处理
        :param i:
        :returns:
    """
    if(i % 15 == 0):
        return np.array([3])
    elif(i % 5 == 0):
        return np.array([2])
    elif(i % 3 == 0):
        return np.array([1])
    else:
        return np.array([0])


def train_and_test(feature_func, label_func):
    """
    使用给定的特征函数以及真值映射函数构建训练集和测试集,并进行训练和测试
    计算误差, 对比与预测值和真实值
        :param feature_func:    特征构造函数
        :param label_func:      真值映射函数
    """
    x_train = np.array([feature_func(i) for i in range(101, 10000)])
    y_train = np.array([label_func(i) for i in range(101, 10000)])

    x_test = np.array([feature_func(i) for i in range(1, 101)])
    y_test = np.array([label_func(i) for i in range(1, 101)])

    regr = linear_model.LinearRegression()
    regr.fit(x_train, y_train)

    y_pred = regr.predict(x_test)

    # print("预测值与真实值对比:\r\n", np.column_stack((y_pred, y_test)))

    print("Mean squared error (均方差-误差): %.2f"
          % mean_squared_error(y_pred, y_test))
    print ("预测值中的最小值:",y_pred.min())
    print ("预测值中的最大值:",y_pred.max())


feature_array = [("使用x本身作为特征向量分量",
                  feature_with_self),

                 ("使用x对3,5,15的取余计算结果作为特征向量的分量",
                  feature_with_complementation),

                 ("使用x对3,5的取余计算结果作为特征向量的分量",
                  feature_with_complementation2),

                 ("判断x对3,5的取余计算结果是否为0,为0--->分量为1,不为0--->分量为0",
                  feature_complementation_is_zero),

                 ("判断x对3,5的取余计算结果是否不为0,为0--->分量为0,不为0--->分量为1",
                  feature_complementation_isnot_zero)]

for tup in feature_array:
    print("-" * 40)
    print(tup[0])
    train_and_test(tup[1], construct_sample_label)
